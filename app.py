import os import json import gradio as gr import pandas as pd import folium import shutil import random import numpy as np from pyproj import Transformer from together import Together from dotenv import load_dotenv from scipy.spatial import ConvexHull from shapely.geometry import Polygon, mapping, MultiPolygon import zipfile import re import rasterio from rasterio.transform import from_origin import matplotlib.pyplot as plt from skimage import measure from sklearn.neighbors import KernelDensity import tempfile print("Starting SpatChat (multi-MCP/KDE, robust download version)") mcp_results = {} kde_results = {} requested_percents = set() requested_kde_percents = set() cached_df = None cached_headers = [] def clear_all_results(): global mcp_results, kde_results, requested_percents, requested_kde_percents mcp_results = {} kde_results = {} requested_percents = set() requested_kde_percents = set() if os.path.exists("outputs"): shutil.rmtree("outputs") os.makedirs("outputs", exist_ok=True) # ========== LLM SETUP (Together API) ========== load_dotenv() client = Together(api_key=os.getenv("TOGETHER_API_KEY")) SYSTEM_PROMPT = """ You are SpatChat, an expert wildlife home range analysis assistant. If the user asks for a home range calculation (MCP, KDE, dBBMM, AKDE, etc.), reply ONLY in JSON using this format: {"tool": "home_range", "method": "mcp", "levels": [95, 50]} - method: one of "mcp", "kde", "akde", "bbmm", "dbbmm" - levels: list of percentages for the home range (default [95] if user doesn't specify) - Optionally, include animal_id if the user specifies a particular animal. For any other questions, answer as an expert movement ecologist in plain text (keep to 2-3 sentences). """ FALLBACK_PROMPT = """ You are SpatChat, a wildlife movement expert. If you can't map a request to a home range tool, just answer naturally. Keep replies under three sentences. """ def ask_llm(chat_history, user_input): messages = [{"role": "system", "content": SYSTEM_PROMPT}] for m in chat_history: messages.append({"role": m["role"], "content": m["content"]}) messages.append({"role": "user", "content": user_input}) resp = client.chat.completions.create( model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free", messages=messages, temperature=0.0 ).choices[0].message.content try: call = json.loads(resp) return call, resp except Exception: conv = client.chat.completions.create( model="meta-llama/Llama-3.3-70B-Instruct-Turbo-Free", messages=[{"role": "system", "content": FALLBACK_PROMPT}] + messages, temperature=0.7 ).choices[0].message.content return None, conv def render_empty_map(): m = folium.Map(location=[0, 0], zoom_start=2, control_scale=True) folium.TileLayer("OpenStreetMap").add_to(m) folium.TileLayer("CartoDB positron", attr='CartoDB').add_to(m) folium.TileLayer( tiles="https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png", attr="OpenTopoMap", name="Topographic" ).add_to(m) folium.TileLayer( tiles="https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}", attr="Esri", name="Satellite" ).add_to(m) folium.LayerControl(collapsed=False).add_to(m) return m._repr_html_() def fit_map_to_bounds(m, df): min_lat, max_lat = df['latitude'].min(), df['latitude'].max() min_lon, max_lon = df['longitude'].min(), df['longitude'].max() if np.isfinite([min_lat, max_lat, min_lon, max_lon]).all(): m.fit_bounds([[min_lat, min_lon], [max_lat, max_lon]]) return m def looks_like_latlon(df, x_col, y_col): try: x_vals = df[x_col].astype(float) y_vals = df[y_col].astype(float) if x_vals.between(-180, 180).all() and y_vals.between(-90, 90).all(): return "lonlat" if x_vals.between(-90, 90).all() and y_vals.between(-180, 180).all(): return "latlon" except Exception: return None return None def looks_invalid_latlon(df, lat_col, lon_col): try: lat = df[lat_col].astype(float) lon = df[lon_col].astype(float) return not (lat.between(-90, 90).all() and lon.between(-180, 180).all()) except Exception: return True def handle_upload_initial(file): global cached_df, cached_headers clear_all_results() os.makedirs("uploads", exist_ok=True) filename = os.path.join("uploads", os.path.basename(file)) shutil.copy(file, filename) try: df = pd.read_csv(filename) cached_df = df cached_headers = list(df.columns) except Exception as e: return [], *(gr.update(visible=False) for _ in range(8)), render_empty_map(), gr.update(visible=False) lower_cols = [col.lower() for col in df.columns] if "latitude" in lower_cols and "longitude" in lower_cols: lat_col = df.columns[lower_cols.index("latitude")] lon_col = df.columns[lower_cols.index("longitude")] if looks_invalid_latlon(df, lat_col, lon_col): return [ {"role": "assistant", "content": "Your columns are labeled latitude and longitude, but the values do not look like geographic coordinates. Please confirm your coordinate system below."} ], \ gr.update(choices=cached_headers, value=lon_col, visible=True), \ gr.update(choices=cached_headers, value=lat_col, visible=True), \ gr.update(visible=True), \ render_empty_map(), \ *(gr.update(visible=True) for _ in range(4)), gr.update(visible=False) else: return [ {"role": "assistant", "content": "CSV uploaded. Latitude and longitude detected. You may now proceed to create home ranges."} ], *(gr.update(visible=False) for _ in range(3)), handle_upload_confirm("longitude", "latitude", ""), *(gr.update(visible=False) for _ in range(4)), gr.update(visible=False) # Try to auto-detect if lat/lon, else require user to specify X/Y and CRS x_names = ["x", "easting", "lon", "longitude"] y_names = ["y", "northing", "lat", "latitude"] found_x = next((col for col in df.columns if col.lower() in x_names), df.columns[0]) found_y = next((col for col in df.columns if col.lower() in y_names and col != found_x), df.columns[1] if len(df.columns) > 1 else df.columns[0]) if found_x == found_y and len(df.columns) > 1: found_y = df.columns[1 if df.columns[0] == found_x else 0] latlon_guess = looks_like_latlon(df, found_x, found_y) if latlon_guess: df["longitude"] = df[found_x] if latlon_guess == "lonlat" else df[found_y] df["latitude"] = df[found_y] if latlon_guess == "lonlat" else df[found_x] cached_df = df return [ {"role": "assistant", "content": f"CSV uploaded. {found_x}/{found_y} interpreted as latitude/longitude."} ], *(gr.update(visible=False) for _ in range(3)), handle_upload_confirm("longitude", "latitude", ""), *(gr.update(visible=False) for _ in range(4)), gr.update(visible=False) return [ {"role": "assistant", "content": f"CSV uploaded. Your coordinates do not appear to be latitude/longitude. Please specify X (easting), Y (northing), and the CRS/UTM zone below."} ], \ gr.update(choices=cached_headers, value=found_x, visible=True), \ gr.update(choices=cached_headers, value=found_y, visible=True), \ gr.update(visible=True), render_empty_map(), *(gr.update(visible=True) for _ in range(4)), gr.update(visible=False) def parse_crs_input(crs_input): crs_input = str(crs_input).strip().upper() if crs_input.startswith("EPSG:"): return int(crs_input.split(":")[1]) if crs_input.isdigit(): return 32600 + int(crs_input) if len(crs_input) >= 2 and crs_input[:-1].isdigit() and crs_input[-1] in ("N", "S"): zone = int(crs_input[:-1]) return 32600 + zone if crs_input[-1] == "N" else 32700 + zone raise ValueError("Invalid CRS input. Use EPSG code or UTM zone like '33N'.") def handle_upload_confirm(x_col, y_col, crs_input): global cached_df df = cached_df.copy() if x_col not in df.columns or y_col not in df.columns: return "<p>Selected coordinate columns not found in data.</p>" if x_col.lower() in ["longitude", "lon"] and y_col.lower() in ["latitude", "lat"]: df['longitude'] = df[x_col] df['latitude'] = df[y_col] else: if not crs_input or crs_input.strip() == "": return "<p>Please enter a CRS or UTM zone before confirming.</p>" try: epsg = parse_crs_input(crs_input) transformer = Transformer.from_crs(epsg, 4326, always_xy=True) df['longitude'], df['latitude'] = transformer.transform( df[x_col].values, df[y_col].values ) except Exception as e: return f"<p>Failed to convert coordinates: {e}</p>" has_timestamp = "timestamp" in df.columns has_animal_id = "animal_id" in df.columns if has_timestamp: df["timestamp"] = pd.to_datetime(df["timestamp"]) if not has_animal_id: df["animal_id"] = "sample" cached_df = df m = folium.Map(location=[df["latitude"].mean(), df["longitude"].mean()], zoom_start=9, control_scale=True) folium.TileLayer("OpenStreetMap").add_to(m) folium.TileLayer("CartoDB positron", attr='CartoDB').add_to(m) folium.TileLayer( tiles="https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png", attr="OpenTopoMap", name="Topographic" ).add_to(m) folium.TileLayer( tiles="https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}", attr="Esri", name="Satellite" ).add_to(m) points_layer = folium.FeatureGroup(name="Points", show=True) lines_layer = folium.FeatureGroup(name="Tracks", show=True) animal_ids = df["animal_id"].unique() color_map = {aid: f"#{random.randint(0, 0xFFFFFF):06x}" for aid in animal_ids} for animal in animal_ids: track = df[df["animal_id"] == animal] coords = list(zip(track["latitude"], track["longitude"])) color = color_map[animal] if has_timestamp: track = track.sort_values("timestamp") folium.PolyLine(coords, color=color, weight=2.5, opacity=0.8, popup=animal).add_to(lines_layer) for _, row in track.iterrows(): label = f"{animal}" + (f"<br>{row['timestamp']}" if has_timestamp else "") folium.CircleMarker( location=[row["latitude"], row["longitude"]], radius=3, popup=label, color=color, fill=True, fill_opacity=0.7 ).add_to(points_layer) points_layer.add_to(m) if has_timestamp: lines_layer.add_to(m) folium.LayerControl(collapsed=False).add_to(m) m = fit_map_to_bounds(m, df) return m._repr_html_() def parse_levels_from_text(text): levels = [int(val) for val in re.findall(r'\b([1-9][0-9]?|100)\b', text)] # Clamp any value > 99 to 99 (for KDE, but also doesn't hurt MCP) levels = [min(l, 99) for l in levels] if not levels: return [95] return sorted(set(levels)) # ========== MCP Functions ========== def mcp_polygon(latitudes, longitudes, percent=95): points = np.column_stack((longitudes, latitudes)) if len(points) < 3: return None centroid = points.mean(axis=0) dists = np.linalg.norm(points - centroid, axis=1) n_keep = max(3, int(len(points) * (percent / 100.0))) keep_idx = np.argsort(dists)[:n_keep] points_kept = points[keep_idx] if len(points_kept) < 3: return None hull = ConvexHull(points_kept) hull_points = points_kept[hull.vertices] return hull_points def add_mcps(df, percent_list): global mcp_results for percent in percent_list: for animal in df["animal_id"].unique(): if animal not in mcp_results: mcp_results[animal] = {} if percent not in mcp_results[animal]: track = df[df["animal_id"] == animal] hull_points = mcp_polygon(track['latitude'].values, track['longitude'].values, percent) if hull_points is not None: poly = Polygon([(lon, lat) for lon, lat in hull_points]) transformer = Transformer.from_crs("epsg:4326", "epsg:3857", always_xy=True) coords_proj = [transformer.transform(lon, lat) for lon, lat in hull_points] poly_proj = Polygon(coords_proj) area_km2 = poly_proj.area / 1e6 mcp_results[animal][percent] = {"polygon": poly, "area": area_km2} # ========== KDE Section ========== def kde_home_range(latitudes, longitudes, percent=95, animal_id="animal", grid_size=200): lon0, lat0 = np.mean(longitudes), np.mean(latitudes) utm_zone = int((lon0 + 180) // 6) + 1 epsg_utm = 32600 + utm_zone if lat0 >= 0 else 32700 + utm_zone to_utm = Transformer.from_crs("epsg:4326", f"epsg:{epsg_utm}", always_xy=True) to_latlon = Transformer.from_crs(f"epsg:{epsg_utm}", "epsg:4326", always_xy=True) x, y = to_utm.transform(longitudes, latitudes) xy = np.vstack([x, y]).T n = xy.shape[0] if n > 1: stds = np.std(xy, axis=0, ddof=1) h = np.power(4 / (3 * n), 1 / 5) * np.mean(stds) if h < 1: h = 30.0 else: h = 30.0 margin = 3 * h xmin, xmax = x.min() - margin, x.max() + margin ymin, ymax = y.min() - margin, y.max() + margin x_grid = np.linspace(xmin, xmax, grid_size) y_grid = np.linspace(ymin, ymax, grid_size) X, Y = np.meshgrid(x_grid, y_grid) grid_points = np.vstack([X.ravel(), Y.ravel()]).T kde = KernelDensity(bandwidth=h, kernel="gaussian") kde.fit(xy) Z = np.exp(kde.score_samples(grid_points)).reshape(X.shape) cell_area = (x_grid[1] - x_grid[0]) * (y_grid[1] - y_grid[0]) Z /= (Z.sum() * cell_area) Z_flat = Z.flatten() idx_desc = np.argsort(Z_flat)[::-1] cumsum = np.cumsum(Z_flat[idx_desc] * cell_area) target = percent / 100.0 idx = min(np.searchsorted(cumsum, target), len(Z_flat[idx_desc]) - 1) threshold = Z_flat[idx_desc][idx] mask = Z >= threshold Z_masked = np.where(mask, Z, 0) total_prob = Z_masked.sum() * cell_area if total_prob > 0: Z_masked /= total_prob contours = measure.find_contours(mask.astype(float), 0.5) polygons = [] for contour in contours: px, py = contour[:, 1], contour[:, 0] utm_xs = np.interp(px, np.arange(grid_size), x_grid) utm_ys = np.interp(py, np.arange(grid_size), y_grid) poly = Polygon(zip(utm_xs, utm_ys)).buffer(0) if poly.is_valid and poly.area > 0: polygons.append(poly) if not polygons: return None, None, None, None, None, None, None from shapely.ops import unary_union mpoly_utm = unary_union(polygons) def utm_poly_to_latlon(poly): if poly.is_empty: return None if isinstance(poly, Polygon): ext_lon, ext_lat = to_latlon.transform(*poly.exterior.xy) interiors = [to_latlon.transform(*interior.xy) for interior in poly.interiors] return Polygon(list(zip(ext_lon, ext_lat)), [list(zip(int_lon, int_lat)) for int_lon, int_lat in interiors]) elif isinstance(poly, MultiPolygon): return MultiPolygon([utm_poly_to_latlon(p) for p in poly.geoms if not p.is_empty]) else: return None mpoly_latlon = utm_poly_to_latlon(mpoly_utm) area_km2 = mpoly_utm.area / 1e6 safe_id = str(animal_id).replace(" ", "_").replace("/", "_") tiff_fp = os.path.join("outputs", f"kde_{safe_id}_{percent}.tif") lon_sw, lat_sw = to_latlon.transform(xmin, ymin) lon_ne, lat_ne = to_latlon.transform(xmax, ymax) with rasterio.open( tiff_fp, "w", driver="GTiff", height=Z_masked.shape[0], width=Z_masked.shape[1], count=1, dtype=Z_masked.dtype, crs="EPSG:4326", transform=from_origin(lon_sw, lat_ne, (lon_ne - lon_sw) / grid_size, (lat_ne - lat_sw) / grid_size) ) as dst: dst.write(np.flipud(Z_masked), 1) geojson_fp = os.path.join("outputs", f"kde_{safe_id}_{percent}.geojson") with open(geojson_fp, "w") as f: json.dump(mapping(mpoly_latlon), f) return mpoly_latlon, area_km2, tiff_fp, geojson_fp, Z_masked, None, None def add_kdes(df, percent_list): global kde_results os.makedirs("outputs", exist_ok=True) for percent in percent_list: for animal in df["animal_id"].unique(): if animal not in kde_results: kde_results[animal] = {} if percent not in kde_results[animal]: track = df[df["animal_id"] == animal] mpoly, area_km2, tiff_fp, geojson_fp, *_ = kde_home_range( track['latitude'].values, track['longitude'].values, percent, animal_id=animal ) if mpoly is not None: kde_results[animal][percent] = { "contour": mpoly, "area": area_km2, "geotiff": tiff_fp, "geojson": geojson_fp } # ========== Main Handlers ========== def handle_chat(chat_history, user_message): global cached_df, mcp_results, kde_results, requested_percents, requested_kde_percents chat_history = list(chat_history) tool, llm_output = ask_llm(chat_history, user_message) mcp_list, kde_list = [], [] method = None # --- Parse tool output for home range requests --- if tool and tool.get("tool") == "home_range": method = tool.get("method") levels = tool.get("levels", [95]) # Clamp all requests at 99 (for KDE/mcp) levels = [min(int(p), 99) for p in levels if 1 <= int(p) <= 100] if method == "mcp": mcp_list = levels elif method == "kde": kde_list = levels # --- Fallback: parse plain user message for explicit % --- if "mcp" in user_message.lower(): mcp_list = parse_levels_from_text(user_message) if "kde" in user_message.lower(): kde_list = parse_levels_from_text(user_message) # --- PATCH: Only require CSV for actual analysis --- if not mcp_list and not kde_list: # Not a home range request; reply as LLM if llm_output: chat_history.append({"role": "user", "content": user_message}) chat_history.append({"role": "assistant", "content": llm_output}) return chat_history, gr.update(), gr.update(visible=False) else: chat_history.append({"role": "assistant", "content": "How can I help you? Please upload a CSV for analysis or ask a question."}) return chat_history, gr.update(), gr.update(visible=False) # --- CSV check: only if doing an analysis --- if cached_df is None or "latitude" not in cached_df or "longitude" not in cached_df: chat_history.append({"role": "assistant", "content": "CSV must be uploaded with 'latitude' and 'longitude' columns."}) return chat_history, gr.update(), gr.update(visible=False) results_exist = False warned_about_kde_100 = False # --- Clamp/Detect KDE 100% requests and set warning --- if kde_list: if 100 in kde_list or any("100" in s for s in user_message.split()): warned_about_kde_100 = True # Clamp all values at 99 kde_list = [min(k, 99) for k in kde_list] # --- Run Analyses --- if mcp_list: add_mcps(cached_df, mcp_list) requested_percents.update(mcp_list) results_exist = True if kde_list: add_kdes(cached_df, kde_list) requested_kde_percents.update(kde_list) results_exist = True # --- Build Map --- df = cached_df m = folium.Map(location=[df["latitude"].mean(), df["longitude"].mean()], zoom_start=9) folium.TileLayer("OpenStreetMap").add_to(m) folium.TileLayer("CartoDB positron", attr='CartoDB').add_to(m) folium.TileLayer( tiles="https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png", attr="OpenTopoMap", name="Topographic" ).add_to(m) folium.TileLayer( tiles="https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}", attr="Esri", name="Satellite" ).add_to(m) points_layer = folium.FeatureGroup(name="Points", show=True) paths_layer = folium.FeatureGroup(name="Tracks", show=True) animal_ids = df["animal_id"].unique() color_map = {aid: f"#{random.randint(0, 0xFFFFFF):06x}" for aid in animal_ids} for animal in animal_ids: track = df[df["animal_id"] == animal] color = color_map[animal] if "timestamp" in track.columns: track = track.sort_values("timestamp") coords = list(zip(track["latitude"], track["longitude"])) if len(coords) > 1: folium.PolyLine(coords, color=color, weight=2.5, opacity=0.8, popup=f"{animal} Track").add_to(paths_layer) for idx, row in track.iterrows(): folium.CircleMarker( location=[row['latitude'], row['longitude']], radius=3, color=color, fill=True, fill_opacity=0.7, popup=f"{animal}" ).add_to(points_layer) points_layer.add_to(m) paths_layer.add_to(m) # MCPs for percent in requested_percents: for animal in animal_ids: if animal in mcp_results and percent in mcp_results[animal]: v = mcp_results[animal][percent] mcp_layer = folium.FeatureGroup(name=f"{animal} MCP {percent}%", show=True) mcp_layer.add_child( folium.Polygon( locations=[(lat, lon) for lon, lat in np.array(v["polygon"].exterior.coords)], color=color_map[animal], fill=True, fill_opacity=0.15 + 0.15 * (percent / 100), popup=f"{animal} MCP {percent}%" ) ) m.add_child(mcp_layer) # ==== KDE: Full raster + all requested contours per animal ==== for animal in animal_ids: kde_percs = [p for p in requested_kde_percents if animal in kde_results and p in kde_results[animal]] if kde_percs: # Use the KDE surface from the highest % requested max_perc = max(kde_percs) v = kde_results[animal][max_perc] raster_layer = folium.FeatureGroup(name=f"{animal} KDE Raster", show=True) with rasterio.open(v["geotiff"]) as src: arr = src.read(1) arr_norm = (arr - arr.min()) / (arr.max() - arr.min() + 1e-10) cmap = plt.get_cmap('plasma') rgba = (cmap(arr_norm) * 255).astype(np.uint8) bounds = src.bounds img = np.dstack([ rgba[:, :, 0], rgba[:, :, 1], rgba[:, :, 2], (rgba[:, :, 3]*0.7).astype(np.uint8) ]) raster_layer.add_child( folium.raster_layers.ImageOverlay( image=img, bounds=[[bounds.bottom, bounds.left], [bounds.top, bounds.right]], opacity=0.7, interactive=False ) ) m.add_child(raster_layer) # Add all requested KDE contours for this animal for percent in kde_percs: v = kde_results[animal][percent] contour_layer = folium.FeatureGroup(name=f"{animal} KDE {percent}% Contour", show=True) contour = v["contour"] if contour: if isinstance(contour, MultiPolygon): for poly in contour.geoms: contour_layer.add_child( folium.Polygon( locations=[(lat, lon) for lon, lat in poly.exterior.coords], color=color_map[animal], fill=True, fill_opacity=0.2, popup=f"{animal} KDE {percent}% Contour" ) ) elif isinstance(contour, Polygon): contour_layer.add_child( folium.Polygon( locations=[(lat, lon) for lon, lat in contour.exterior.coords], color=color_map[animal], fill=True, fill_opacity=0.2, popup=f"{animal} KDE {percent}% Contour" ) ) m.add_child(contour_layer) folium.LayerControl(collapsed=False).add_to(m) m = fit_map_to_bounds(m, df) map_html = m._repr_html_() msg = [] if mcp_list: msg.append(f"MCP home ranges ({', '.join(str(p) for p in mcp_list)}%) calculated.") if kde_list: msg.append(f"KDE home ranges ({', '.join(str(p) for p in kde_list)}%) calculated (raster & contours).") if warned_about_kde_100: msg.append("Note: KDE at 100% is not supported and has been replaced by 99% for compatibility (as done in scientific software).") chat_history.append({"role": "user", "content": user_message}) chat_history.append({"role": "assistant", "content": " ".join(msg) + " Download all results below."}) # --- Always generate the ZIP with current results for DownloadButton --- archive_path = save_all_mcps_zip() return chat_history, gr.update(value=m._repr_html_()), gr.update(value=archive_path, visible=results_exist) # ========== ZIP Results ========== def save_all_mcps_zip(): os.makedirs("outputs", exist_ok=True) features = [] rows = [] geojson_path = None if any(mcp_results.values()): for animal, percents in mcp_results.items(): for percent, v in percents.items(): features.append({ "type": "Feature", "properties": { "animal_id": animal, "percent": percent, "area_km2": v["area"] }, "geometry": mapping(v["polygon"]) }) rows.append((animal, f"MCP-{percent}", v["area"])) geojson = {"type": "FeatureCollection", "features": features} geojson_path = os.path.join("outputs", "mcps_all.geojson") with open(geojson_path, "w") as f: json.dump(geojson, f) for animal, percents in kde_results.items(): for percent, v in percents.items(): rows.append((animal, f"KDE-{percent}", v["area"])) csv_path = None if rows: df = pd.DataFrame(rows, columns=["animal_id", "type", "area_km2"]) csv_path = os.path.join("outputs", "home_range_areas.csv") df.to_csv(csv_path, index=False) archive = "outputs/spatchat_results.zip" if os.path.exists(archive): os.remove(archive) with zipfile.ZipFile(archive, "w", zipfile.ZIP_DEFLATED) as zipf: for root, _, files in os.walk("outputs"): for file in files: if file.endswith('.zip'): continue full_path = os.path.join(root, file) rel_path = os.path.relpath(full_path, "outputs") zipf.write(full_path, arcname=rel_path) print("ZIP written:", archive) return archive # ========== UI ========== with gr.Blocks(title="SpatChat: Home Range Analysis") as demo: gr.Image( value="logo_long1.png", show_label=False, show_download_button=False, show_share_button=False, type="filepath", elem_id="logo-img" ) gr.HTML(""" <style> #logo-img img { height: 90px; margin: 10px 50px 10px 10px; border-radius: 6px; } </style> """) gr.Markdown("## 🏠 SpatChat: Home Range Analysis {hr} 🦊🦉🐢") gr.HTML(""" <div style="margin-top: -10px; margin-bottom: 15px;"> <input type="text" value="https://spatchat.org/browse/?room=hr" id="shareLink" readonly style="width: 50%; padding: 5px; background-color: #f8f8f8; color: #222; font-weight: 500; border: 1px solid #ccc; border-radius: 4px;"> <button onclick="navigator.clipboard.writeText(document.getElementById('shareLink').value)" style="padding: 5px 10px; background-color: #007BFF; color: white; border: none; border-radius: 4px; cursor: pointer;"> 📋 Copy Share Link </button> <div style="margin-top: 10px; font-size: 14px;"> <b>Share:</b> <a href="https://twitter.com/intent/tweet?text=Checkout+Spatchat!&url=https://spatchat.org/browse/?room=hr" target="_blank">🐦 Twitter</a> | <a href="https://www.facebook.com/sharer/sharer.php?u=https://spatchat.org/browse/?room=hr" target="_blank">📘 Facebook</a> </div> </div> """) gr.Markdown(""" <div style="font-size: 14px;"> © 2025 Ho Yi Wan & Logan Hysen. All rights reserved.<br> If you use Spatchat in research, please cite:<br> <b>Wan, H.Y.</b> & <b>Hysen, L.</b> (2025). <i>SpatChat: Home Range Analysis.</i> </div> """) with gr.Row(): with gr.Column(scale=2): chatbot = gr.Chatbot( label="SpatChat", show_label=True, type="messages", value=[{"role": "assistant", "content": "Welcome to SpatChat! Please upload a CSV containing coordinates (lat/lon or UTM) and optional timestamp/animal_id to begin."}] ) user_input = gr.Textbox( label="Ask Spatchat", placeholder="Type commands...", lines=1 ) file_input = gr.File( label="Upload Movement CSV (.csv or .txt only)", file_types=[".csv", ".txt"] ) x_col = gr.Dropdown(label="X column", choices=[], visible=False) y_col = gr.Dropdown(label="Y column", choices=[], visible=False) crs_input = gr.Text(label="CRS (e.g. '32633', '33N', or 'EPSG:32633')", visible=False) confirm_btn = gr.Button("Confirm Coordinate Settings", visible=False) with gr.Column(scale=3): map_output = gr.HTML(label="Map Preview", value=render_empty_map(), show_label=False) # ========== FIX: DownloadButton only has label/visible, NO fn here ========== download_btn = gr.DownloadButton( "📥 Download Results", value=None, # no initial file, will be set by the handler visible=False # stays hidden until results ready ) file_input.change( fn=handle_upload_initial, inputs=file_input, outputs=[ chatbot, x_col, y_col, crs_input, map_output, x_col, y_col, crs_input, confirm_btn, download_btn ] ) confirm_btn.click( fn=handle_upload_confirm, inputs=[x_col, y_col, crs_input], outputs=map_output ) user_input.submit( fn=handle_chat, inputs=[chatbot, user_input], outputs=[chatbot, map_output, download_btn] ) user_input.submit(lambda *args: "", inputs=None, outputs=user_input) demo.launch(ssr_mode=False)